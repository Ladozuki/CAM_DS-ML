{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8IqRn5Ly-dA"
      },
      "source": [
        "\n",
        "**First things first** - please go to 'File' and select 'Save a copy in Drive' so that you have your own version of this activity set up and ready to use.\n",
        "Remember to update the portfolio index link to your own work once completed!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j5Bse6izKKh"
      },
      "source": [
        "# Mini-project 6.3 Applying supervised learning to predict student dropout rate\n",
        "\n",
        "**Welcome to your Mini-project: Applying supervised learning to predict student dropout rate!**\n",
        "\n",
        "In this project, we will examine student data and use supervised learning techniques to predict whether a student will drop out. In the education sector, retaining students is vital for the institution's financial stability and for students’ academic success and personal development. A high dropout rate can lead to significant revenue loss, diminished institutional reputation, and lower overall student satisfaction.\n",
        "\n",
        "Please set aside approximately **12 hours** to complete the mini-project.\n",
        "\n",
        "<br></br>\n",
        "\n",
        "## **Business context**\n",
        "Study Group specialises in providing educational services and resources to students and professionals across various fields. The company's primary focus is on enhancing learning experiences through a range of services, including online courses, tutoring, and educational consulting. By leveraging cutting-edge technology and a team of experienced educators, Study Group aims to bridge the gap between traditional learning methods and the evolving needs of today's learners.\n",
        "\n",
        "Study Group serves its university partners by establishing strategic partnerships to enhance the universities’ global reach and diversity. It supports the universities in their efforts to attract international students, thereby enriching the cultural and academic landscape of their campuses. It works closely with university faculty and staff to ensure that the universities are prepared and equipped to welcome and support a growing international student body. Its partnership with universities also offers international students a seamless transition into their chosen academic environment. Study Group runs several International Study Centres across the UK and Dublin in partnership with universities with the aim of preparing a pipeline of talented international students from diverse backgrounds for degree study. These centres help international students adapt to the academic, cultural, and social aspects of studying abroad. This is achieved by improving conversational and subject-specific language skills and academic readiness before students progress to a full degree programme at university.\n",
        "\n",
        "Through its comprehensive suite of services, it supports learners and universities at every stage of their educational journey, from high school to postgraduate studies. Its approach is tailored to meet the unique needs of each learner, offering personalised learning paths and flexible scheduling options to accommodate various learning styles and commitments.\n",
        "\n",
        "Study Group's services are designed to be accessible and affordable, making quality education a reality for many individuals. By focusing on the integration of technology and personalised learning, the company aims to empower learners to achieve their full potential and succeed in their academic and professional pursuits. Study Group is at the forefront of transforming how people learn and grow through its dedication to innovation and excellence.\n",
        "Study Group has provided you a course-level data set.\n",
        "\n",
        "\n",
        "<br></br>\n",
        "\n",
        "## **Objective**\n",
        "By the end of this mini-project, you will have developed the skills and knowledge to apply advanced machine learning techniques to create a predictive model for student dropout. This project will involve comprehensive data exploration, preprocessing, and feature engineering to ensure high-quality input for the models. You will employ and compare multiple predictive algorithms - XGBoost and neural network-based model, to determine the most effective model for predicting student dropout.\n",
        "\n",
        "In the Notebook, you will:\n",
        "- explore the data set\n",
        "- preprocess the data and conduct feature engineering\n",
        "- predict dropout using XGBoost, and neural network-based model\n",
        "- Identify the most important predictors of dropout.\n",
        "\n",
        "\n",
        "You will also write a report summarising the results of your findings and recommendations.\n",
        "\n",
        "<br></br>\n",
        "\n",
        "## **Assessment criteria**\n",
        "By completing this project, you will be able to provide evidence that you can:\n",
        "- develop accurate predictions across diverse organisational scenarios by building and testing advanced machine learning models\n",
        "- inform data-driven decision-making with advanced machine learning algorithms and models\n",
        "- propose and present effective solutions to organisational problems using data preprocessing, model selection, and insightful analysis techniques.\n",
        "\n",
        "<br></br>\n",
        "\n",
        "## **Project guidance**\n",
        "\n",
        "Data preparation\n",
        "1. Import the required libraries and data set with the provided URL.\n",
        "  - Data set drive: https://drive.google.com/drive/folders/130AVMFxTOtRiC7GOl7QmSo0I7B0iChv5\n",
        "2. Read the course-level csv file and make it available as a dataframe.\n",
        "\n",
        "3. From the dataframe, remove the following columns:\n",
        "\n",
        "columns= ['BookingId','BookingType', 'LeadSource', 'DiscountType',\n",
        "                                                    'Nationality', 'HomeCountry',\n",
        "                                                    'HomeState',\n",
        "                                                    'HomeCity',\n",
        "                                                    'PresentCount',\n",
        "                                                    'LateCount', 'AuthorisedAbsenceCount','ArrivedDate','NonCompletionReason',\n",
        "                                                    'TerminationDate',\n",
        "                                                    'CourseFirstIntakeDate', 'CourseStartDate','CourseEndDate',\n",
        "                                                    'AcademicYear', 'CourseName',\n",
        "                                                    'LearnerCode', 'ProgressionDegree',\n",
        "                                                    'EligibleToProgress',\n",
        "                                                    'AssessedModules',\n",
        "                                                    'PassedModules',\n",
        "                                                    'FailedModules',\n",
        "                                                    'AttendancePercentage',\n",
        "                                                    'ContactHours']\n",
        "\n",
        "From here on, you will perform the rest of the actvities mentioned in the rubric with the smaller set of features obtained after performing the above step.\n",
        "\n",
        "General Instructions that apply throughout this project activity:\n",
        "  - Use the standard scaler to scale your numeric input features.\n",
        "  - Split the data into train and test sets. Apply 80-20 split.\n",
        "  - Print accuracy, confusion matrix, precision, recall and AUC on the test set\n",
        "    for all your models.\n",
        "  - Compare the performance (on the test set) obtained from the non-optimised\n",
        "    model with the best performing model. Record your observations. What differences do you see and which metrics are improved or not improved?\n",
        "\n",
        "## Please refer to the Rubric for specific steps to be performed as part of the project activity. Every step mentioned in the rubric will be assessed separately.\n",
        "\n",
        "Report\n",
        "1. Document your approach and major inferences from the data analysis and describe which method provided the best results and why.\n",
        "  - Please ensure you include a discussion around which of the features will predict student droput.\n",
        "2. When you’ve completed the project:\n",
        "  - Download your completed Notebook as an IPYNB (Jupyter Notebook) or PY (Python) file. Save the file as follows: **LastName_FirstName_CAM_C201_Week_6_Mini-project**.\n",
        "  - Prepare a detailed report (between 800-1,000 words) that includes:\n",
        "    - an overview of your approach\n",
        "    - a description of your analysis\n",
        "    - an explanation of the insights you identified\n",
        "    - a summary of which method gave the best results\n",
        "    - an explanation of visualisations you created.\n",
        "  - Save the document as a PDF named according to the following convention: **LastName_FirstName_CAM_C201_Week_6_Mini-project.pdf**.\n",
        "  \n",
        "\n",
        "\n",
        "<br></br>\n",
        "> **Declaration**\n",
        ">\n",
        "> By submitting your project, you indicate that the work is your own and has been created with academic integrity. Refer to the Cambridge plagiarism regulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E94GxaOEU-BC"
      },
      "outputs": [],
      "source": [
        "# Standard libraries (if applicable)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "\n",
        "# Machine Learning libraries\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# TensorFlow / Keras libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "HkzP_xPrU1HR",
        "outputId": "23d65683-91ec-42cf-bcee-20c9903064d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a713571a-64cd-454f-b5ba-56f8d8f8df5b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a713571a-64cd-454f-b5ba-56f8d8f8df5b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "upload =  files.upload()\n",
        "\n",
        "filename = next(iter(uploaded))\n",
        "\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPiORXhUU1D1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbH_KzwLU1Ah"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul6AZ7hIU099"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nr_bj7PU07F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKlXRGJxU037"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu_3xygCU0un"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}